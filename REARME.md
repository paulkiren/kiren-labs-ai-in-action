# AI in Action: Start with Ollama + Local Model Fine-tuning

## Why This Approach is Ideal for Learning

- **Runs entirely on your M4 chip**  
    Leverage excellent GPU acceleration for efficient training and inference.

- **Comprehensive Workflow**  
    Covers data preprocessing, model training, inference, and deployment.

- **Real-World Applicable Skills**  
    Gain hands-on experience with tools and techniques used in production environments.

- **Full Control Over the Pipeline**  
    Understand and manage every step, from raw data to deployed model.

---

Get started by setting up [Ollama](https://ollama.com/) and exploring local model fine-tuning on your machine!